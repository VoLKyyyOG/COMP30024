{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2019 Semester 1\n",
    "-----\n",
    "## Project 1: Gaining Information about Naive Bayes\n",
    "-----\n",
    "###### Student Name(s): Akira and Callum\n",
    "###### Python version: 3.7.1 from Anaconda \n",
    "###### Submission deadline: 1pm, Fri 5 Apr 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you may use for your Project 1 submission. (You are not required to use it; in particular, there is no need to use iPython if you do not like it.)\n",
    "\n",
    "Marking will be applied on the five functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The cell below supresses forced output scrolling so you can see view the script output easier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have specifically imported all functions below to ensure we implemented iteratively AND without the use of external functions wherever possible**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from collections import defaultdict\n",
    "from numpy import NaN\n",
    "from math import log\n",
    "\n",
    "########## POSSIBLE CSVs ##########\n",
    "d1 =  'anneal.csv'\n",
    "h1 = 'family,product-type,steel,carbon,hardness,temper_rolling,condition,formability,strength,non-ageing,surface-finish,surface-quality,enamelability,bc,bf,bt,bw-me,bl,m,chrom,phos,cbond,marvi,exptl,ferro,corr,bbvc,lustre,jurofm,s,p,shape,oil,bore,packing,class'.split(',')\n",
    "\n",
    "d2 =  'breast-cancer.csv'\n",
    "h2 = 'age,menopause,tumor-size,inv-nodes,node-caps,deg-malig,breast,breast-quad,irradiat,class'.split(',')\n",
    "\n",
    "d3 =  'car.csv'\n",
    "h3 = 'buying,maint,doors,persons,lug_boot,safety,class'.split(',')\n",
    "\n",
    "d4 =  'cmc.csv'\n",
    "h4 = 'w-education,h-education,n-child,w-relation,w-work,h-occupation,standard-of-living,media-exposure,class'.split(',')\n",
    "\n",
    "d5 =  'hepatitis.csv'\n",
    "h5 = 'sex,steroid,antivirals,fatigue,malaise,anorexia,liver-big,liver-firm,spleen-palpable,spiders,ascites,varices,histology,class'.split(',')\n",
    "\n",
    "d6 =  'hypothyroid.csv'\n",
    "h6 = 'sex,on-thyroxine,query-on-thyroxine,on_antithyroid,surgery,query-hypothyroid,query-hyperthyroid,pregnant,sick,tumor,lithium,goitre,TSH,T3,TT4,T4U,FTI,TBG,class'.split(',')\n",
    "\n",
    "d7 =  'mushroom.csv'\n",
    "h7 = 'cap-shape,cap-surface,cap-color,bruises,odor,gill-attachment,gill-spacing,gill-size,gill-color,stalk-shape,stalk-root,stalk-surface-above-ring,stalk-surface-below-ring,stalk-color-above-ring,stalk-color-below-ring,veil-type,veil-color,ring-number,ring-type,spore-print-color,population,habitat,class'.split(',')\n",
    "\n",
    "d8 =  'nursery.csv'\n",
    "h8 = 'parents,has_nurs,form,children,housing,finance,social,health,class'.split(',')\n",
    "\n",
    "d9 = 'primary-tumor.csv'\n",
    "h9 = 'age,sex,histologic-type,degree-of-diffe,bone,bone-marrow,lung,pleura,peritoneum,liver,brain,skin,neck,supraclavicular,axillar,mediastinum,abdominal,class'.split(',')\n",
    "\n",
    "datasets = [d1,d2,d3,d4,d5,d6,d7,d8,d9]\n",
    "dataset_headers = [h1,h2,h3,h4,h5,h6,h7,h8,h9]\n",
    "\n",
    "dictionary = {datasets[i] : dataset_headers[i] for i in range(len(datasets))}\n",
    "\n",
    "\"\"\"Sets the column of each dataset\"\"\"\n",
    "def set_column(filename):\n",
    "    return dictionary[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Has been adjusted so that it works with testing on the train data, and partitioning for cross_val\"\"\"\n",
    "def preprocess(filename, testing_on_train = True, k = 10, drop = 'no', impute = 'no'):\n",
    "    # Add column headers, drop columns with only one unique value (all same value)\n",
    "    df = read_csv(filename, header = None, names = set_column(filename))\n",
    "    df.replace('?', NaN, inplace=True)\n",
    "    \n",
    "    #### ONLY USED FOR QUESTION 6 - NOT FOR FUNCTIONALITY ####\n",
    "    if impute in 'yesYesYES':    \n",
    "        print(f\"Number of missing values: {df.isna().sum().sum()}\")\n",
    "        mode = df.mode().iloc[0]\n",
    "        for col in df.columns[:-1]:\n",
    "            mode = df[col].mode()\n",
    "            df[col].fillna(mode)\n",
    "    ##########################################################\n",
    "    \n",
    "    \"\"\"If we are not using the cross validation method\"\"\"\n",
    "    # Return the whole dataset as a dataframe\n",
    "    if testing_on_train:\n",
    "        return df\n",
    "    else:\n",
    "        \"\"\"Drop no gain attributes given the input in the script\"\"\"\n",
    "        if drop in 'yesYesYES':\n",
    "            non_unique = df.apply(Series.nunique)\n",
    "            df.drop(non_unique[non_unique == 1].index, axis=1, inplace=True)\n",
    "            \n",
    "        temp = df.copy()\n",
    "        partitions = list()\n",
    "        \n",
    "        # k-fold Cross Validation\n",
    "        divisor = k\n",
    "        \n",
    "        for i in range(k):\n",
    "            partitions.append(temp.sample(frac=1/divisor))\n",
    "            divisor -= 1\n",
    "            temp.drop(partitions[-1].index, axis=0, inplace=True)\n",
    "        \n",
    "        del temp\n",
    "        \n",
    "        # Dictionary of train/test pairs\n",
    "        cross_validation_pairs = defaultdict(list)\n",
    "        models = list()\n",
    "        \n",
    "        for i in range(k):\n",
    "            test = partitions[i]\n",
    "            train = df.iloc[df.index.drop(test.index.values)]\n",
    "            cross_validation_pairs[\"train\"].append(train)\n",
    "            cross_validation_pairs[\"test\"].append(test)\n",
    "            \n",
    "        return cross_validation_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trains a model given a training dataset\"\"\"\n",
    "def train(train_set):\n",
    "    N = len(train_set)\n",
    "    priors = {}\n",
    "    posteriors = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "    \"\"\"Accessable using posteriors[class j][attribute x][value i]\"\"\"\n",
    "    \n",
    "    for label in train_set['class'].unique():\n",
    "        priors[label] = len(train_set.loc[train_set['class'] == label]) / N\n",
    "        for attribute in train_set.columns[:-1]:\n",
    "            temp = train_set.loc[train_set['class'] == label, [attribute,'class']]\n",
    "            n = len(temp)\n",
    "            \n",
    "            count = defaultdict(int)\n",
    "            for i in temp[attribute]:\n",
    "                if i != NaN:\n",
    "                    count[i] += 1\n",
    "            \n",
    "            for i in count:\n",
    "                posteriors[label][attribute][i] = count[i] / n\n",
    "                \n",
    "    trained_model = {\"priors\": priors, \"posteriors\": posteriors}\n",
    "    \n",
    "    return trained_model\n",
    "\n",
    "\"\"\"Trains M partitions for cross_val\"\"\"\n",
    "def cross_validation_train(cross_validation_pairs):\n",
    "    trained_models = list()\n",
    "    train_set = cross_validation_pairs[\"train\"]\n",
    "    test_set = cross_validation_pairs[\"test\"]\n",
    "    N = len(train_set)\n",
    "    \n",
    "    for i in range(N):\n",
    "        trained_models.append(train(train_set[i]))\n",
    "        \n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Predicts a test set\"\"\"\n",
    "def predict(trained_model, test_set):\n",
    "    priors = trained_model[\"priors\"]\n",
    "    posteriors = trained_model[\"posteriors\"]\n",
    "    \n",
    "    \"\"\"Drop the class labels of the test set\"\"\"\n",
    "    test_labels = test_set['class']\n",
    "    test = test_set.drop('class', axis=1)\n",
    "    cols = test_set.columns\n",
    "    \n",
    "    \"\"\"Probabilistic Smoothing with epsilon -> 0\"\"\"\n",
    "    n = len(test_labels)\n",
    "    epsilon = 1e-100\n",
    "    \n",
    "    \"\"\"Model Prediction\"\"\"\n",
    "    prediction = {}\n",
    "    \n",
    "    \"\"\"The Predicted Labels to be Returned\"\"\"\n",
    "    \"\"\"(Key, Value) = (Test Instance Row, Predicted Label)\"\"\"\n",
    "    predicted_labels = {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        instance = test.iloc[i]\n",
    "        for label in priors.keys():       \n",
    "            prob = log(priors[label])/log(2)\n",
    "            for attribute in cols:\n",
    "                try:\n",
    "                    \"\"\"If the value is non missing\"\"\"\n",
    "                    if instance[attribute] != NaN:\n",
    "                        prob += log(posteriors[label][attribute][instance[attribute]])/log(2)\n",
    "                    else:\n",
    "                        \"\"\"Otherwise we have chosen to simply ignore it\"\"\"\n",
    "                        pass\n",
    "                except:\n",
    "                    \"\"\"If the value does not exist in our model, we use epsilon\"\"\"\n",
    "                    prob += log(epsilon)/log(2)\n",
    "                    \n",
    "            prediction[label] = prob\n",
    "        \n",
    "        \"\"\"Choose the predicted class with the highest probability\"\"\"\n",
    "        predicted_labels[i] = max(prediction, key=prediction.get)\n",
    "        \n",
    "    return predicted_labels\n",
    "\n",
    "\"\"\"Tests partitions\"\"\"\n",
    "def cross_validation_predict(trained_models, cross_validation_pairs):\n",
    "    test_set = cross_validation_pairs[\"test\"]\n",
    "    N = len(test_set)\n",
    "    predictions = list()\n",
    "    \n",
    "    for i in range(N):\n",
    "        predictions.append(predict(trained_models[i], test_set[i]))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Evaluates the accuracy\"\"\"\n",
    "def evaluate(predicted_labels, test_set):\n",
    "    test_labels = test_set['class']\n",
    "    n = len(test_labels)\n",
    "    \n",
    "    return [1 if predicted_labels[i] == test_labels.iloc[i] else 0 for i in range(n)]\n",
    "\n",
    "\"\"\"Evaluates cross_val accuracy\"\"\"\n",
    "def cross_validation_evaluate(predictions, cross_pairs):\n",
    "    test = cross_pairs[\"test\"]\n",
    "    N = len(test)\n",
    "    results = list()\n",
    "    for i in range(N):\n",
    "        results.append(evaluate(predictions[i], test[i]))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculates the entropy given a series\"\"\"\n",
    "def entropy(distribution):\n",
    "    # Calculates the entropy (uncertainty) of an event (class) for a given distribution \n",
    "    # (e.g. distribution given a certain attribute value)\n",
    "    N = len(distribution)\n",
    "    # Normalise and count values iteratively\n",
    "    count = defaultdict(int)\n",
    "    for i in distribution:\n",
    "        count[i] += 1\n",
    "    event = [i/N for i in count.values()]\n",
    "    \n",
    "    return (-1*sum([i*log(i)/log(2) for i in event]))\n",
    "\n",
    "\"\"\"Calculates the mean information given a dataset\"\"\"\n",
    "def mean_info(dataset):\n",
    "    mean_info_per_attribute = defaultdict(float)\n",
    "    \n",
    "    for attribute in dataset.columns[:-1]:\n",
    "        # Used to calculate 'probability' of said value for a random instance (number of values / total number of instances)\n",
    "        \n",
    "        attribute_value_counts = defaultdict(int)\n",
    "        for i in dataset[attribute]:\n",
    "            attribute_value_counts[i] += 1\n",
    "            \n",
    "        N = len(dataset[attribute])\n",
    "        for value in dataset[attribute].unique():\n",
    "            # dataframe.loc on said value and return the corresponding class column\n",
    "            corresponding_values = dataset.loc[dataset[attribute] == value, 'class']\n",
    "            # add (probability of said value * entropy of said value) to the attribute's mean info\n",
    "            mean_info_per_attribute[attribute] += attribute_value_counts[value]/N * entropy(corresponding_values)\n",
    "            \n",
    "    return mean_info_per_attribute\n",
    "\n",
    "\"\"\"Calculates the information gain given a dataset. Adjusted so that it can drop 0 info_gain columns\"\"\"\n",
    "def info_gain(dataset, drop_no_gain = False):\n",
    "    mean_info_per_attribute = mean_info(dataset) # Weighted sum of child stump entropies if split on each attribute\n",
    "    class_entropy = entropy(dataset['class']) # H(R), the entropy of class distribution prior to splitting\n",
    "    info_gain_given_class = defaultdict(float)\n",
    "    \n",
    "    for attribute in mean_info_per_attribute:\n",
    "        # Calculates IG(attribute) for the dataset's class\n",
    "        info_gain_given_class[attribute] = class_entropy - mean_info_per_attribute[attribute]\n",
    "    \n",
    "    \"\"\"If we want to drop the columns with absolutely 0 information gain\"\"\"\n",
    "    if drop_no_gain:\n",
    "        non_unique = dataset.apply(Series.nunique)\n",
    "        dataset.drop(non_unique[non_unique == 1].index, axis=1, inplace=True)\n",
    "        return dataset\n",
    "    else:\n",
    "        return info_gain_given_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_attributes(distribution):\n",
    "    N = len(distribution)\n",
    "    \n",
    "    count = defaultdict(int)\n",
    "    for i in distribution:\n",
    "        count[i] += 1\n",
    "    event = [i/N for i in count.values()]\n",
    "    \n",
    "    return (-1*sum([i*log(i)/log(2) for i in event]))\n",
    "\n",
    "def mean_info_attributes(dataset, column_name):\n",
    "    mean_info_per_attribute = defaultdict(float)\n",
    "    \n",
    "    # We want every OTHER attribute \n",
    "    cols = [i for i in dataset.columns if i != column_name]\n",
    "    \n",
    "    for attribute in cols: # class label has been dropped already\n",
    "        \n",
    "        attribute_value_counts = defaultdict(int)\n",
    "        for i in dataset[attribute]:\n",
    "            attribute_value_counts[i] += 1\n",
    "            \n",
    "        N = len(dataset[attribute])\n",
    "        for value in dataset[attribute].unique():\n",
    "            corresponding_values = dataset.loc[dataset[attribute] == value, attribute]\n",
    "            mean_info_per_attribute[attribute] += attribute_value_counts[value]/N * entropy_attributes(corresponding_values)\n",
    "            \n",
    "    return mean_info_per_attribute\n",
    "\n",
    "def info_gain_attributes(dataset, to_print = 'no'):\n",
    "    temp = dataset.drop('class', axis=1)\n",
    "    \n",
    "    entropy_per_attribute = defaultdict(float)\n",
    "    all_IG = defaultdict(float) # Me change\n",
    "    \n",
    "    for attribute in temp.columns:\n",
    "        # a dictionary of H(R)\n",
    "        entropy_per_attribute[attribute] = entropy(temp[attribute])\n",
    "        \n",
    "        mean_info_per_attribute = mean_info_attributes(temp, attribute)\n",
    "        \n",
    "    for attribute in entropy_per_attribute:\n",
    "        if to_print in 'yesYesYES': # Me change\n",
    "            print(f\"Entropy({attribute}) = {entropy_per_attribute[attribute]:.4f}\\n\")\n",
    "        average = list()\n",
    "        for every_other_attribute in mean_info_per_attribute:\n",
    "            info = entropy_per_attribute[attribute] - mean_info_per_attribute[every_other_attribute]\n",
    "            average.append(info)\n",
    "            if to_print in 'yesYesYES':\n",
    "                print(f\"InfoGain({every_other_attribute} | {attribute}) = {info:.4f}\")\n",
    "        \n",
    "        if to_print in 'yesYesYES': # Me change\n",
    "            print(f\"\\nAverage Info Gain for {attribute} to every other attribute is {sum(average)/len(mean_info_per_attribute):.4f}\")\n",
    "            print(\"*\"*40)\n",
    "        \n",
    "        all_IG[attribute]= sum(average)/len(mean_info_per_attribute) # Me change\n",
    "    return all_IG # Me change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is a script that runs every dataset and tests on its training, as well as k-fold cross-validation for a given _k_. It will also ask (y/n) for printing relevant information gain, and to drop attributes with 0 information gain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "Enter k value for k-Fold Cross Validation: 10\n",
      "Drop all columns with absolutely no information gain? (y/n): n\n",
      "Print the information gain for class? (y/n): n\n",
      "Impute missing values? (y/n): n\n",
      "****************************************\n",
      "Processing anneal.csv ...\n",
      "For anneal.csv:\n",
      "Number of rows: 898\n",
      "Number of attributes/columns: 36\n",
      "Information Gain for Class:\n",
      "Average: 0.0882, Best 0.4352, Worst 0.0000, Variance 0.0143\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 0.4917, Best 2.0508, Worst 0.0000, Vairance 0.3170\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 99.11%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 97.78% 100.00% 97.78% 98.89% 98.89% 98.89% 98.89% 100.00% 98.89% 100.00%\n",
      "Average 10-Fold Cross Validation Accuracy: 99.00%\n",
      "****************************************\n",
      "Processing breast-cancer.csv ...\n",
      "For breast-cancer.csv:\n",
      "Number of rows: 286\n",
      "Number of attributes/columns: 10\n",
      "Information Gain for Class:\n",
      "Average: 0.0377, Best 0.0801, Worst 0.0020, Variance 0.0010\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 1.5285, Best 3.0244, Worst 0.7913, Vairance 0.4640\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 75.52%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 75.86% 62.07% 75.00% 75.86% 85.71% 62.07% 78.57% 58.62% 75.00% 68.97%\n",
      "Average 10-Fold Cross Validation Accuracy: 71.77%\n",
      "****************************************\n",
      "Processing car.csv ...\n",
      "For car.csv:\n",
      "Number of rows: 1728\n",
      "Number of attributes/columns: 7\n",
      "Information Gain for Class:\n",
      "Average: 0.1144, Best 0.2622, Worst 0.0045, Variance 0.0090\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 1.7925, Best 2.0000, Worst 1.5850, Vairance 0.0431\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 87.38%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 86.13% 81.50% 87.28% 84.39% 88.44% 88.44% 83.72% 86.13% 84.30% 88.44%\n",
      "Average 10-Fold Cross Validation Accuracy: 85.88%\n",
      "****************************************\n",
      "Processing cmc.csv ...\n",
      "For cmc.csv:\n",
      "Number of rows: 1473\n",
      "Number of attributes/columns: 9\n",
      "Information Gain for Class:\n",
      "Average: 0.0380, Best 0.1017, Worst 0.0026, Variance 0.0010\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 1.3798, Best 2.4929, Worst 0.3807, Vairance 0.4531\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 50.58%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 49.66% 42.18% 47.62% 59.86% 49.32% 48.98% 48.65% 48.98% 50.00% 50.34%\n",
      "Average 10-Fold Cross Validation Accuracy: 49.56%\n",
      "****************************************\n",
      "Processing hepatitis.csv ...\n",
      "For hepatitis.csv:\n",
      "Number of rows: 155\n",
      "Number of attributes/columns: 14\n",
      "Information Gain for Class:\n",
      "Average: 0.0735, Best 0.1516, Worst 0.0138, Variance 0.0018\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 0.8968, Best 1.2799, Worst 0.4791, Vairance 0.0433\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 84.52%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 62.50% 80.00% 75.00% 80.00% 93.75% 86.67% 93.75% 80.00% 87.50% 80.00%\n",
      "Average 10-Fold Cross Validation Accuracy: 81.92%\n",
      "****************************************\n",
      "Processing hypothyroid.csv ...\n",
      "For hypothyroid.csv:\n",
      "Number of rows: 3163\n",
      "Number of attributes/columns: 19\n",
      "Information Gain for Class:\n",
      "Average: 0.0025, Best 0.0094, Worst 0.0000, Variance 0.0000\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 0.3578, Best 1.0119, Worst 0.0076, Vairance 0.0636\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 95.23%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 95.89% 93.67% 96.52% 96.20% 95.57% 94.95% 93.35% 94.95% 95.89% 95.27%\n",
      "Average 10-Fold Cross Validation Accuracy: 95.23%\n",
      "****************************************\n",
      "Processing mushroom.csv ...\n",
      "For mushroom.csv:\n",
      "Number of rows: 8124\n",
      "Number of attributes/columns: 23\n",
      "Information Gain for Class:\n",
      "Average: 0.2115, Best 0.9061, Worst 0.0000, Variance 0.0433\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 1.4432, Best 3.0304, Worst 0.0000, Vairance 0.6580\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 99.72%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 99.75% 99.63% 99.63% 99.26% 100.00% 99.75% 99.63% 99.63% 99.88% 99.75%\n",
      "Average 10-Fold Cross Validation Accuracy: 99.69%\n",
      "****************************************\n",
      "Processing nursery.csv ...\n",
      "For nursery.csv:\n",
      "Number of rows: 12960\n",
      "Number of attributes/columns: 9\n",
      "Information Gain for Class:\n",
      "Average: 0.1615, Best 0.9588, Worst 0.0043, Variance 0.0945\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 1.7077, Best 2.3219, Worst 1.0000, Vairance 0.1387\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 90.31%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 90.28% 90.90% 90.20% 89.27% 91.51% 89.74% 90.90% 89.12% 90.82% 90.51%\n",
      "Average 10-Fold Cross Validation Accuracy: 90.32%\n",
      "****************************************\n",
      "Processing primary-tumor.csv ...\n",
      "For primary-tumor.csv:\n",
      "Number of rows: 339\n",
      "Number of attributes/columns: 18\n",
      "Information Gain for Class:\n",
      "Average: 0.3282, Best 2.0948, Worst 0.0204, Variance 0.2428\n",
      "Interdependence Between Attribute Pairs:\n",
      "Average: 0.8143, Best 1.7590, Worst 0.1451, Vairance 0.1487\n",
      "\n",
      "TESTING ON THE TRAIN DATA\n",
      "Accuracy for Testing on the Training Data: 61.65%\n",
      "\n",
      "10-FOLD CROSS VALIDATION\n",
      "Accuracy using k-Fold Cross Validation: 50.00% 50.00% 41.18% 52.94% 35.29% 47.06% 52.94% 50.00% 38.24% 39.39%\n",
      "Average 10-Fold Cross Validation Accuracy: 45.70%\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "print(\"*\"*40)\n",
    "k = int(input(\"Enter k value for k-Fold Cross Validation: \"))\n",
    "\"\"\"DO WE WANT TO DROP 0 INFO GAIN ATTRIBUTES?\"\"\"\n",
    "drop = input(\"Drop all columns with absolutely no information gain? (y/n): \").lower()\n",
    "\"\"\"DO WE WANT TO PRINT THE INFO GAIN?\"\"\"\n",
    "to_print = input(\"Print the information gain for class? (y/n): \").lower()\n",
    "\"\"\"DO WE WANT TO IMPUTE MISSING VALUES FOR THE TRAINING SET\"\"\"\n",
    "to_impute = input(\"Impute missing values? (y/n): \").lower()\n",
    "print(\"*\"*40)\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "# ONLY FOR ANSWERING QUESTIONS AND ANALYSING RESULTS\n",
    "from numpy import var, array\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "ig = defaultdict(float)\n",
    "acc = defaultdict(float)\n",
    "avg_ig = defaultdict(float)\n",
    "\n",
    "for data in datasets:\n",
    "    print(f\"Processing {data} ...\")\n",
    "    \n",
    "    df = preprocess(data, impute = to_impute)\n",
    "    if drop in 'yesYesYES':\n",
    "        df = info_gain(df, drop_no_gain = True)\n",
    "        info_gain_given_class = info_gain(df)\n",
    "    else:\n",
    "        info_gain_given_class = info_gain(df)\n",
    "    if to_print in 'yesYesYES':\n",
    "        for attribute in info_gain_given_class:\n",
    "            print(f'InfoGain({attribute} | class) = {info_gain_given_class[attribute]:.4f}')\n",
    "        print('...')\n",
    "\n",
    "    IG_per_attr = info_gain_attributes(df)\n",
    "    \n",
    "    avg_ig[data] = sum(info_gain_given_class.values())/len(info_gain_given_class)\n",
    "    \n",
    "    print(f\"For {data}:\") # Me change\n",
    "    print(\"Number of rows: %d\" % len(df))\n",
    "    print(\"Number of attributes/columns: %d\" % len(df.columns))\n",
    "    print(\"Information Gain for Class:\")\n",
    "    print(f\"Average: {sum(info_gain_given_class.values())/len(info_gain_given_class):.4f}, Best {max(info_gain_given_class.values()):.4f}, Worst {min(info_gain_given_class.values()):.4f}, Variance {var(array(list(info_gain_given_class.values()))):.4f}\")\n",
    "    print(\"Interdependence Between Attribute Pairs:\")\n",
    "    print(f\"Average: {sum(IG_per_attr.values())/len(IG_per_attr):.4f}, Best {max(IG_per_attr.values()):.4f}, Worst {min(IG_per_attr.values()):.4f}, Vairance {var(array(list(IG_per_attr.values()))):.4f}\") # Me change\n",
    "\n",
    "    ig[data] = sum(IG_per_attr.values())/len(IG_per_attr)\n",
    "    \n",
    "    print(\"\\nTESTING ON THE TRAIN DATA\")\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"TRAIN / TEST\"\"\"\n",
    "    model = train(df)\n",
    "    prediction = predict(model, df)\n",
    "    results = evaluate(prediction, df)\n",
    "    print(f\"Accuracy for Testing on the Training Data: {100*sum(results)/len(results):.2f}%\")\n",
    "    \n",
    "    acc[data] = 100*sum(results)/len(results)\n",
    "    \n",
    "    \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "    print(f\"\\n{k}-FOLD CROSS VALIDATION\")\n",
    "\n",
    "    cross_validation_pairs = preprocess(data, testing_on_train = False, k = k, drop = drop)\n",
    "    trained_models = cross_validation_train(cross_validation_pairs)\n",
    "    predictions = cross_validation_predict(trained_models, cross_validation_pairs)\n",
    "    cross_validation_results = cross_validation_evaluate(predictions, cross_validation_pairs)\n",
    "    print(\"Accuracy using k-Fold Cross Validation: \" + \" \".join([f\"{100*sum(i) / len(i):.2f}%\" for i in cross_validation_results]))\n",
    "    print(f\"Average {k}-Fold Cross Validation Accuracy: {sum([100*sum(i) / len(i) for i in cross_validation_results]) / len(cross_validation_results):.2f}%\")\n",
    "    print(\"*\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.099463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.099463</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.000000 -0.099463\n",
       "1 -0.099463  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapper = defaultdict(list)\n",
    "for i in avg_ig.keys():\n",
    "    mapper[i].append(avg_ig[i])\n",
    "    mapper[i].append(acc[i])\n",
    "mapper.values()\n",
    "\n",
    "plt.scatter([i[0] for i in mapper.values()], [i[1] for i in mapper.values()])\n",
    "plt.title(\"Information Gain\")\n",
    "plt.xlabel(\"Average IG for class\")\n",
    "plt.ylabel(\"Naive Bayes Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(DataFrame.from_dict(mapper).T.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.521974</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.000000  0.521974\n",
       "1  0.521974  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "priors = list()\n",
    "for i in datasets:\n",
    "    df = preprocess(i)\n",
    "    model =train(df)['priors']\n",
    "    priors.append(100*model[max(model, key=model.get)])\n",
    "    \n",
    "mapper1 = defaultdict(list)\n",
    "l = [i[1] for i in mapper.values()]\n",
    "for i in range(len(datasets)):\n",
    "    mapper1[i].append(priors[i])\n",
    "    mapper1[i].append(l[i])\n",
    "\n",
    "plt.scatter([i[0] for i in mapper1.values()], [i[1] for i in mapper1.values()])\n",
    "plt.title(\"Prior\")\n",
    "plt.xlabel(\"Prior Probabilities\")\n",
    "plt.ylabel(\"Naive Bayes Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#display(DataFrame.from_dict(mapper1).T.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = avg ig\n",
    "y = acc - prior*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.165815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.165815</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  1.000000 -0.165815\n",
       "1 -0.165815  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapper = defaultdict(list)\n",
    "for i in ig.keys():\n",
    "    mapper[i].append(ig[i])\n",
    "    mapper[i].append(acc[i])\n",
    "mapper.values()\n",
    "plt.scatter([i[0] for i in mapper.values()], [i[1] for i in mapper.values()])\n",
    "plt.title(\"Naive Bayes Assumption Proof\")\n",
    "plt.xlabel(\"Average IG between Attribute Pairs\")\n",
    "plt.ylabel(\"Naive Bayes Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "display(DataFrame.from_dict(mapper).T.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Questions 1, 2, 4 and 6 (150 - 200 words for each response):\n",
    "\n",
    "#### 1. The Naive Bayes classifiers can be seen to vary, in terms of their effectiveness on the given datasets (e.g. in terms of Accuracy). Consider the Information Gain of each attribute, relative to the class distribution  does this help to explain the classifiers behaviour? Identify any results that are particularly surprising, and explain why they occur.\n",
    "In theory, we should expect a higher accuracy if more data is available, since there is more information for the model to use. But in our findings above, we find that the whether Information Gain was low or high did not significantly impact accuracy. \n",
    "\n",
    "This can be seen with `primary-tumor.csv` with low performance , compared to `mushroom.csv` where there is one attribute with `0.9` information gain, and the rest between `0.1 - 0.4` and some less than `0.1`. \n",
    "\n",
    "\n",
    "\n",
    "##\n",
    "There are exceptions however, `hypothyroid.csv` whose attributes have very little information gain despite high Naive Bayes classification accuracy. This can be attributed due to the sheer number of `Negative` labels compared to `Hypothyroid` (95.22 to 4.78), where Naive Bayes seems to degenerate to Zero-R because the posterior probabilities are so low that it becomes dependent on the priors.\n",
    "##\n",
    "\n",
    "low entropy = low accuracy, high entropy = high accuracy \n",
    "\n",
    "\n",
    "Although information gain is quite mininmal between attributes, it could be that the relationship accross \n",
    "\n",
    "We noticed that datasets with higher number of instances and attributes performed better (strictly in terms of label prediction accuracy). According to the Information Gain for each attribute given class, we found it to have a `-0.09` correlation which is conventionally considered **weak**.\n",
    "\n",
    "Due to the nature of Naive Bayes and its assumption on \"conditional independence\", it multiplies its posteriors with priors. \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#### 2. The Information Gain can be seen as a kind of correlation coefficient between a pair of attributes: when the gain is low, the attribute values are uncorrelated; when the gain is high, the attribute values are correlated. In supervised ML, we typically calculate the Infomation Gain between a single attribute and the class, but it can be calculated for any pair of attributes. Using the pair-wise IG as a proxy for attribute interdependence, in which cases are our NB assumptions violated? Describe any evidence (or indeed, lack of evidence) that this is has some effect on the effectiveness of the NB classifier.\n",
    "In any given dataset, two attributes may depend on each other, but the dependence may be distributed evenly within the attributes. In this case, we can see that the Naive Bayes's assumption of conditional independence is violated. If we just look at two attributes, there may be a strong dependence between them that can affect the classification. However, if you take into account the dependencies when classifying all together, they may cancel each other out and not affect the classification. \n",
    "\n",
    "From this, we can argue that it is the distribution of the attribute dependencies, rather than the dependencies between attributes (pair-wise IG) that affect the Naive Bayes Classification (correlation does not imply causation, there may be an underlying distribution). If you look at the graph above, we can also see that across all the datasets, there seems to be no evidence that the Information Gain between attributes plays a role in affecting accuracy. If anything, a look at the correlation table suggests that there is a **W\\weak** relationship between pair-wise IG and the performance of our model (in terms of accuracy). \n",
    "\n",
    "As such, there is a lack of evidence that it has some effect on the effectiveness of the Naive Bayes classifier.\n",
    "    \n",
    "\n",
    "#### 4. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a holdout or crossvalidation evaluation strategy. How does your estimate of effectiveness change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "Implementation: $k$-Fold Cross-Validation\n",
    "    \n",
    "In theory, we should expect a higher accuracy if more data is available, since there is more information for the model to use. This means that testing our model on the training data would be the *best case scenario* for accuracy, since our supervised model has seen everything prior to testing. If we take this into account, then our $k$-Fold Cross Validation does a reasonable job (typically a 2% difference or even equal performance in accuracy using $k$ = 10) despite being partitioned.  The reason as to why $k$-Fold Cross Validation seems to perform better than a Hold-Out strategy can be accounted by:\n",
    "- The *random noise* which $k$-Fold Cross Validation can successfully reduce since it is averaging over the $k$ sets of estimations\n",
    "- Unlike Hold-Out, where a split of the data is used, the fact that every training instance is eventually used as a testing instance in a partition means that our model is not missing out on any information overall\n",
    "    \n",
    "\n",
    "#### 6. Naive Bayes is said to elegantly handle missing attribute values. For the datasets with missing values, is there any evidence that the performance is different on the instances with missing values, compared to the instances where all of the values are present? Does it matter which, or how many values are missing? Would an imputation strategy have any effect on this?\n",
    "To an extent, it does not matter how many values are missing, but more if the attribute with the missing values has a high information gain or not. This may be since missing values in itself could be significant (i.e. because there is a missing value, it could lead to a specific class label). \n",
    "\n",
    "For datasets with missing values, we used a mode (freqeuncy) imputation to fill in missing values since most were categorical - this means that the datasets with more missing values would have their models become slightly more biased.\n",
    "\n",
    "The graphs and table below suggest that the imputation using mode has little or no impact on evaluation (strictly in terms of label prediction accuracy). There are a total of 5 datasets with missing values; with 2 near identical, 2 with a negative impact and one with a positive impact.\n",
    "The only positive impact is when testing using the $k$-Fold Cross-Validation method, which may ultimately be due to its ability to reduce random noise, predominantly seen in the `primary-tumour.csv`. The testing on the training data had no impact whatsoever as expected due to the nature of supervised learning algorithms (explained in Q1/2). \n",
    "\n",
    "This backs the claim that the Naive Bayes is able to elegantly handle missing attribute values, without the need of imputations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 results\n",
    "Training on test is the exact same with or without imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "df = read_csv('results.csv').set_index('Unnamed: 0')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "df[df.columns[1::2]].plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
